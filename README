1. Create a Kubernetes cluster on GCP (GCP gives free credits on signup so those should suffice for this
exercise). If possible share a script / code which can be used to create the cluster.

$ gcloud config project noble-function-185508
$ gcloud config set compute/zone us-west1-a
$ gcloud container clusters create my-cluster
$ gcloud container clusters get-credentials my-cluster


2.Install nginx ingress controller on the cluster. For now, we consider that the user will add public IP of
ingress LoadBalancer to their /etc/hosts file for all hostnames to be used. So do not worry about DNS
resolution.

$ kubectl create clusterrolebinding cluster-admin-binding \
  --clusterrole cluster-admin \
  --user $(gcloud config get-value account)
$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml


3. On this cluster, create namespaces called staging and production.

$ kubectl create ns staging
$ kubectl create ns production


4. Install guest-book application on both namespaces. 	

$ kubectl apply -f https://k8s.io/examples/application/guestbook/redis-master-deployment.yaml -n staging
$ kubectl apply -f https://k8s.io/examples/application/guestbook/redis-master-service.yaml -n staging
$ kubectl apply -f https://k8s.io/examples/application/guestbook/redis-slave-deployment.yaml -n staging
$ kubectl apply -f https://k8s.io/examples/application/guestbook/redis-slave-service.yaml -n staging
$ kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-deployment.yaml -n staging
$ kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-service.yaml -n staging
$ kubectl get pods  -n staging
$ kubectl get svc -n staging

$ kubectl apply -f https://k8s.io/examples/application/guestbook/redis-master-deployment.yaml -n production
$ kubectl apply -f https://k8s.io/examples/application/guestbook/redis-master-service.yaml -n production
$ kubectl apply -f https://k8s.io/examples/application/guestbook/redis-slave-deployment.yaml -n production
$ kubectl apply -f https://k8s.io/examples/application/guestbook/redis-slave-service.yaml -n production
$ kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-deployment.yaml -n production
$ kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-service.yaml -n production
$ kubectl get pods  -n production
$ kubectl get svc -n production


5. Expose staging application on hostname staging-guestbook.mstakx.io - staging.yaml

apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: my-ingress
  namespace: staging
  annotations:
     kubernetes.io/ingress.class: nginx
spec:
  rules:
  - host: staging-guestbook.mstakx.io
    http:
      paths:
      - path: /
        backend:
          serviceName: frontend
          servicePort: 80

$ kubectl apply -f staging.yaml


6. Expose production application on hostname guestbook.mstakx.io - production.yaml

apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: my-ingress
  namespace: production
  annotations:
     kubernetes.io/ingress.class: nginx
spec:
  rules:
  - host: guestbook.mstakx.io
    http:
      paths:
      - path: /
        backend:
          serviceName: frontend
          servicePort: 80

$ kubectl apply -f production.yaml


7. Implement a pod autoscaler on both namespaces which will scale frontend pod replicas up and down
based on CPU utilization of pods. 

$ kubectl autoscale deploy frontend --min=2 --max=5 --cpu-percent=80 -n staging 
$ kubectl get hpa

$ kubectl autoscale deploy frontend --min=2 --max=5 --cpu-percent=80 -n production
$ kubectl get hpa -n production


8. Write a script which will demonstrate how the pods are scaling up and down by increasing/decreasing load
on existing pods. (not sure about it)

$ kubectl get hpa/frontend -n staging -o yaml > load.yaml
$ change the replicaset in yaml up or dwn
$ kubectl apply -f load.yaml -n staging

or 

$ kubectl edit hpa/frontend -n staging and change the replicaset in yaml up or dwn
